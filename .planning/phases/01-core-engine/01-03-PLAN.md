---
phase: 01-core-engine
plan: 03
type: execute
wave: 2
depends_on: ["01-02"]
files_modified:
  - src/configurable_agents/config/schema.py
  - src/configurable_agents/config/validator.py
  - src/configurable_agents/config/__init__.py
  - src/configurable_agents/core/graph_builder.py
  - src/configurable_agents/core/control_flow.py
  - src/configurable_agents/core/parallel.py
  - src/configurable_agents/core/__init__.py
  - src/configurable_agents/runtime/feature_gate.py
  - src/configurable_agents/runtime/executor.py
  - tests/core/test_graph_builder.py
  - tests/core/test_control_flow.py
  - tests/core/test_parallel.py
  - tests/config/test_schema.py
  - tests/config/test_validator.py
autonomous: true

must_haves:
  truths:
    - "User can write a YAML config with conditional edges (routes) and the workflow follows the correct branch based on node output"
    - "User can write a YAML config with a retry loop and the workflow repeats a node until a condition is met or max iterations reached"
    - "User can write a YAML config where multiple nodes execute concurrently and all results are collected before continuing"
    - "Existing linear workflows continue to work exactly as before"
  artifacts:
    - path: "src/configurable_agents/core/control_flow.py"
      provides: "Routing functions for conditional branching and loop logic"
      exports: ["create_routing_function", "create_loop_router"]
    - path: "src/configurable_agents/core/parallel.py"
      provides: "Send object factories for parallel fan-out execution"
      exports: ["create_fan_out_function"]
    - path: "src/configurable_agents/core/graph_builder.py"
      provides: "Updated graph builder supporting conditional edges, loops, and parallel nodes"
      contains: "add_conditional_edges"
    - path: "src/configurable_agents/config/validator.py"
      provides: "Updated validator supporting routes, loop edges, and parallel edges"
      contains: "validate_conditional_edges"
  key_links:
    - from: "src/configurable_agents/core/graph_builder.py"
      to: "src/configurable_agents/core/control_flow.py"
      via: "routing functions passed to add_conditional_edges"
      pattern: "create_routing_function|create_loop_router"
    - from: "src/configurable_agents/core/graph_builder.py"
      to: "src/configurable_agents/core/parallel.py"
      via: "Send factories for fan-out edges"
      pattern: "create_fan_out_function"
    - from: "src/configurable_agents/config/validator.py"
      to: "src/configurable_agents/config/schema.py"
      via: "validates route conditions and parallel config"
      pattern: "validate_conditional_edges|validate_parallel"
---

<objective>
Implement advanced control flow in the LangGraph execution engine: conditional branching (if/else routing), loop support (retry/iteration with termination), and parallel node execution (fan-out/fan-in via Send objects).

Purpose: RT-01 (branching), RT-02 (loops), and RT-03 (parallelism) are the three remaining core runtime requirements for Phase 1. These transform the system from a linear pipeline runner into a real workflow orchestration engine. The existing schema already has RouteCondition and Route models defined but gated by feature_gate.py -- this plan removes the gate and implements the runtime.

Output: Updated graph_builder.py supporting all three control flow patterns, new control_flow.py and parallel.py modules, updated config validation, and comprehensive tests.
</objective>

<execution_context>
@C:\Users\ghost\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\ghost\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-engine/01-RESEARCH.md
@.planning/phases/01-core-engine/01-02-SUMMARY.md
@src/configurable_agents/core/graph_builder.py
@src/configurable_agents/core/node_executor.py
@src/configurable_agents/config/schema.py
@src/configurable_agents/config/validator.py
@src/configurable_agents/runtime/feature_gate.py
@src/configurable_agents/runtime/executor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend config schema and validation for advanced control flow</name>
  <files>
    src/configurable_agents/config/schema.py
    src/configurable_agents/config/validator.py
    src/configurable_agents/config/__init__.py
    src/configurable_agents/runtime/feature_gate.py
    tests/config/test_schema.py
    tests/config/test_validator.py
  </files>
  <action>
1. Update `src/configurable_agents/config/schema.py`:

   **Enhance RouteCondition model** (already exists but needs refinement):
   - Keep `logic: str` field but add description: "Python-like condition expression referencing state fields (e.g., 'state.score > 0.8') or 'default' for fallback route"

   **Enhance Route model** (already exists):
   - Already has `condition: RouteCondition` and `to: str` -- this is sufficient

   **Add LoopConfig model** (new):
   ```python
   class LoopConfig(BaseModel):
       """Loop configuration for retry/iteration edges."""
       max_iterations: int = Field(10, gt=0, le=100, description="Maximum loop iterations before forced exit")
       condition_field: str = Field(..., description="State field to evaluate for loop termination (must be bool)")
       exit_to: str = Field("END", description="Node to route to when loop condition is met or max iterations reached")
   ```

   **Add ParallelConfig model** (new):
   ```python
   class ParallelConfig(BaseModel):
       """Parallel execution configuration for fan-out edges."""
       items_field: str = Field(..., description="State field containing list of items to fan out over")
       target_node: str = Field(..., description="Node to execute for each item")
       collect_field: str = Field(..., description="State field to collect results into (must be list type)")
   ```

   **Update EdgeConfig model:**
   - Add: `loop: Optional[LoopConfig] = Field(None, description="Loop configuration (retry/iteration)")`
   - Add: `parallel: Optional[ParallelConfig] = Field(None, description="Parallel fan-out configuration")`
   - Update `validate_to_or_routes` validator to allow: exactly one of `to`, `routes`, `loop`, or `parallel` is set. Current validator checks for `to` XOR `routes`. Extend to: exactly one of the four must be specified.

   Export LoopConfig and ParallelConfig from config/__init__.py.

2. Update `src/configurable_agents/config/validator.py`:

   Add validation for new edge types in `validate_config()`:

   **validate_conditional_edges:**
   - For edges with `routes`: verify each route.to is a valid node ID or "END"
   - Verify at least one route has `condition.logic == "default"` (fallback required)
   - Verify condition.logic references only state fields that exist in state schema (basic check: split by operators, check field names against state.fields)

   **validate_loop_edges:**
   - For edges with `loop`: verify `loop.condition_field` exists in state schema and is type "bool"
   - Verify `loop.exit_to` is a valid node ID or "END"
   - Verify the edge `from_` node exists

   **validate_parallel_edges:**
   - For edges with `parallel`: verify `parallel.items_field` exists in state schema and is a list type (type string starts with "list")
   - Verify `parallel.target_node` is a valid node ID
   - Verify `parallel.collect_field` exists in state schema and is a list type
   - Verify target_node has appropriate output configuration

   These validations should be called from the existing `validate_config()` function. Add them as separate helper functions following the existing pattern (_validate_edges, _validate_nodes, etc.).

3. Update `src/configurable_agents/runtime/feature_gate.py`:

   **Remove the hard block on conditional routing:**
   - In `_check_conditional_routing()`, remove the `raise UnsupportedFeatureError` for edges with routes. This feature is now supported.
   - Either delete the function entirely or convert it to a no-op/pass-through.

   **Update `get_supported_features()`:**
   - Move "Conditional routing (if/else)" from `not_supported.v0.2` to `flow_control`
   - Move "Loops and retries" from `not_supported.v0.2` to `flow_control`
   - Add "Parallel node execution (fan-out/fan-in)" to `flow_control`
   - Remove these from `not_supported` entirely

4. Update tests:

   **tests/config/test_schema.py:** Add tests for:
   - LoopConfig creation with valid fields
   - LoopConfig max_iterations validation (0 rejected, 101 rejected, 50 accepted)
   - ParallelConfig creation with valid fields
   - EdgeConfig with loop config (valid)
   - EdgeConfig with parallel config (valid)
   - EdgeConfig with multiple config types (routes + loop) raises ValueError
   - EdgeConfig with routes (already tested, verify still works)

   **tests/config/test_validator.py:** Add tests for:
   - Conditional edge with valid routes passes validation
   - Conditional edge missing default route fails
   - Conditional edge referencing non-existent node fails
   - Loop edge with valid condition_field passes
   - Loop edge with non-bool condition_field fails
   - Loop edge with non-existent exit_to fails
   - Parallel edge with valid list items_field passes
   - Parallel edge with non-list items_field fails
   - Parallel edge with non-existent target_node fails
  </action>
  <verify>
Run `pytest tests/config/test_schema.py -v` -- all schema tests pass (new + existing).
Run `pytest tests/config/test_validator.py -v` -- all validator tests pass (new + existing).
Run `python -c "from configurable_agents.config import LoopConfig, ParallelConfig; print('schema OK')"` -- imports work.
  </verify>
  <done>
Config schema supports conditional routes, loops, and parallel edges. Validator enforces correct field references and types. Feature gate no longer blocks conditional routing. All config tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement conditional branching and loop control flow runtime</name>
  <files>
    src/configurable_agents/core/control_flow.py
    src/configurable_agents/core/__init__.py
    tests/core/test_control_flow.py
  </files>
  <action>
1. Create `src/configurable_agents/core/control_flow.py`:

   **create_routing_function(routes: List[Route], state_fields: Dict[str, str]) -> Callable:**
   Returns a function that evaluates route conditions against current state and returns the target node name.

   Implementation:
   ```python
   def create_routing_function(routes, state_fields):
       def routing_fn(state):
           state_dict = state.model_dump() if hasattr(state, 'model_dump') else dict(state)
           default_target = None
           for route in routes:
               if route.condition.logic == "default":
                   default_target = route.to
                   continue
               # Evaluate condition against state
               # Use a SAFE evaluator -- NOT eval()
               if _evaluate_condition(route.condition.logic, state_dict):
                   return route.to if route.to != "END" else END
           if default_target:
               return default_target if default_target != "END" else END
           raise ValueError("No matching route and no default route")
       return routing_fn
   ```

   **_evaluate_condition(logic: str, state: dict) -> bool:**
   Safe condition evaluator. Supports:
   - Comparison: `state.field > value`, `state.field == "string"`, `state.field < 10`
   - Boolean: `state.field` (truthy check), `not state.field`
   - Compound: `state.field > 0.5 and state.other == "yes"`

   Implementation approach: Parse the condition string, replace `state.X` references with actual values from the state dict, then evaluate using a restricted subset. Do NOT use `eval()` or `exec()`. Instead:
   - Use `ast.literal_eval` for value parsing
   - Write a simple expression parser that handles: field references, comparisons (>, <, >=, <=, ==, !=), boolean operators (and, or, not), string/number literals
   - Raise `ValueError` for unsupported expressions rather than silently failing

   **create_loop_router(loop_config: LoopConfig, from_node: str) -> Callable:**
   Returns a routing function for loop edges:
   ```python
   def create_loop_router(loop_config, from_node):
       iteration_key = f"_loop_iteration_{from_node}"
       def loop_fn(state):
           state_dict = state.model_dump() if hasattr(state, 'model_dump') else dict(state)
           iteration = state_dict.get(iteration_key, 0)
           condition_met = state_dict.get(loop_config.condition_field, False)
           if condition_met or iteration >= loop_config.max_iterations:
               return loop_config.exit_to if loop_config.exit_to != "END" else END
           return from_node  # Loop back
       return loop_fn
   ```

   Note: The loop iteration counter needs to be tracked in state. The graph builder (Task 3) will add a hidden `_loop_iteration_{node}` field to the state model for loop edges.

2. Update `src/configurable_agents/core/__init__.py`:
   - Export new functions: `create_routing_function`, `create_loop_router`

3. Write tests in `tests/core/test_control_flow.py`:
   - Test _evaluate_condition with simple comparisons: `"state.score > 0.8"` with state {"score": 0.9} -> True
   - Test _evaluate_condition with equality: `"state.status == 'approved'"` -> True/False
   - Test _evaluate_condition with boolean: `"state.is_ready"` -> True when truthy
   - Test _evaluate_condition with compound: `"state.score > 0.5 and state.approved"` -> True when both true
   - Test _evaluate_condition rejects dangerous expressions (no function calls, no imports)
   - Test create_routing_function: given routes, verify correct target returned for different states
   - Test create_routing_function: default route used when no condition matches
   - Test create_routing_function: raises ValueError when no match and no default
   - Test create_loop_router: returns from_node when condition not met and iterations < max
   - Test create_loop_router: returns exit_to when condition met
   - Test create_loop_router: returns exit_to when max_iterations reached
  </action>
  <verify>
Run `pytest tests/core/test_control_flow.py -v` -- all control flow tests pass.
Run `python -c "from configurable_agents.core import create_routing_function, create_loop_router; print('control flow OK')"` -- imports work.
  </verify>
  <done>
Conditional branching routing functions evaluate state-based conditions safely (no eval/exec). Loop router tracks iteration counts and exits on condition or max iterations. All control flow tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement parallel execution and integrate all control flow into graph builder</name>
  <files>
    src/configurable_agents/core/parallel.py
    src/configurable_agents/core/graph_builder.py
    src/configurable_agents/core/__init__.py
    tests/core/test_parallel.py
    tests/core/test_graph_builder.py
  </files>
  <action>
1. Create `src/configurable_agents/core/parallel.py`:

   **create_fan_out_function(parallel_config: ParallelConfig) -> Callable:**
   Returns a function that creates Send objects for parallel execution:
   ```python
   from langgraph.types import Send

   def create_fan_out_function(parallel_config):
       def fan_out_fn(state):
           state_dict = state.model_dump() if hasattr(state, 'model_dump') else dict(state)
           items = state_dict.get(parallel_config.items_field, [])
           if not items:
               return []  # No items to process
           return [
               Send(parallel_config.target_node, {
                   **state_dict,
                   "_parallel_item": item,
                   "_parallel_index": i,
               })
               for i, item in enumerate(items)
           ]
       return fan_out_fn
   ```

   Note: Each parallel invocation gets the full state plus `_parallel_item` (current item) and `_parallel_index`. The target node should reference `{_parallel_item}` in its prompt template.

   **Result collection:** LangGraph's Send objects execute nodes in parallel. Results are collected via a reducer on the collect_field. The graph builder will configure a state annotation with `operator.add` reducer for the collect_field.

2. Update `src/configurable_agents/core/graph_builder.py`:

   **Remove `_validate_linear_flow()` call** from `build_graph()`. The system now supports non-linear flows.

   **Update `_add_edge()` to handle all edge types:**
   Rename to `_add_edges()` (plural) and process each edge based on its type:

   - **Linear edge** (has `to`): Use existing `graph.add_edge(from_node, to_node)` logic
   - **Conditional edge** (has `routes`): Use `graph.add_conditional_edges(from_node, routing_fn)` where routing_fn is from `create_routing_function(edge.routes, state_fields)`
   - **Loop edge** (has `loop`): Use `graph.add_conditional_edges(from_node, loop_fn)` where loop_fn is from `create_loop_router(edge.loop, from_node)`. Also need to: (a) add the loop-back edge, (b) inject `_loop_iteration_{node}` into state, (c) add an incrementer wrapper around the node function
   - **Parallel edge** (has `parallel`): Use `graph.add_conditional_edges(from_node, fan_out_fn)` where fan_out_fn is from `create_fan_out_function(edge.parallel)`

   **Handle loop iteration tracking:**
   For loop edges, the graph builder needs to:
   - Add a hidden state field `_loop_iteration_{from_node}: int = 0` to the state model
   - Wrap the target node function to increment the counter on each execution
   - This may require dynamically augmenting the state_model. Use Pydantic's `create_model()` to add the field.

   **Handle parallel result collection:**
   For parallel edges, configure the state with a reducer annotation for `collect_field`:
   - Import `from typing import Annotated` and `import operator`
   - The state schema needs `Annotated[list, operator.add]` for the collect field
   - This must be set up when building the StateGraph

   **Update `build_graph()` signature and flow:**
   ```python
   def build_graph(config, state_model, global_config=None, tracker=None):
       # Defensive validation (updated, no linear flow check)
       _validate_config_for_graph(config)

       # Augment state model for loops (add iteration counters)
       state_model = _augment_state_for_loops(state_model, config.edges)

       # Augment state model for parallelism (add reducers)
       state_model = _augment_state_for_parallel(state_model, config.edges)

       # Create StateGraph
       graph = StateGraph(state_model)

       # Add nodes
       for node_config in config.nodes:
           node_fn = make_node_function(node_config, global_config, tracker)
           # Wrap with loop counter if this node is a loop target
           if _is_loop_target(node_config.id, config.edges):
               node_fn = _wrap_with_loop_counter(node_fn, node_config.id)
           graph.add_node(node_config.id, node_fn)

       # Add edges (all types)
       for edge in config.edges:
           _add_edges(graph, edge, config)

       # Compile and return
       return graph.compile()
   ```

3. Update `src/configurable_agents/core/__init__.py`:
   - Export new function: `create_fan_out_function`

4. Write tests:

   **tests/core/test_parallel.py:**
   - Test create_fan_out_function: returns correct number of Send objects for items list
   - Test create_fan_out_function: each Send has correct target node and state
   - Test create_fan_out_function: empty items list returns empty list
   - Test _parallel_item and _parallel_index present in Send state

   **tests/core/test_graph_builder.py (update existing):**
   - Keep all existing linear flow tests (they must still pass)
   - Add: test build_graph with conditional edges (mock nodes, verify routing)
   - Add: test build_graph with loop edge (mock node, verify loop executes multiple times and exits)
   - Add: test build_graph with parallel edge (mock node, verify fan-out creates sends)
   - Add: test that _validate_linear_flow is no longer called (or removed)

   Use mocks for LLM calls. Test the graph compilation and routing logic, not actual LLM execution.
  </action>
  <verify>
Run `pytest tests/core/test_parallel.py -v` -- all parallel tests pass.
Run `pytest tests/core/test_graph_builder.py -v` -- all graph builder tests pass (existing + new).
Run `pytest tests/ -v --tb=short` -- full test suite passes (zero regressions).
  </verify>
  <done>
Parallel execution fans out via LangGraph Send objects with result collection via state reducers. Graph builder supports all four edge types (linear, conditional, loop, parallel). Existing linear workflows unaffected. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/config/ -v` -- all config tests pass (schema + validator for new edge types)
2. `pytest tests/core/ -v` -- all core tests pass (control_flow, parallel, graph_builder)
3. `pytest tests/ -v --tb=short` -- full test suite passes (zero regressions)
4. Feature gate: `get_supported_features()['flow_control']` includes conditional routing, loops, parallel
5. A YAML config with conditional routes parses and validates successfully
6. A YAML config with loop config parses and validates successfully
7. A YAML config with parallel config parses and validates successfully
8. Existing linear YAML configs continue to parse, validate, and (with mocked LLM) execute
</verification>

<success_criteria>
- Conditional branching: routing functions evaluate state-based conditions and direct flow to correct nodes
- Loop support: nodes repeat with iteration tracking, exit on condition or max iterations
- Parallel execution: fan-out via Send objects, results collected via state reducers
- Safe condition evaluation: no eval/exec, restricted expression parser
- Backward compatible: all existing linear workflows work unchanged
- Config validation catches invalid routes, loop configs, and parallel configs at parse time
- All tests pass (new + existing, zero regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-engine/01-03-SUMMARY.md`
</output>

---
phase: 07-cli-testing-and-fixes
plan: 03
type: execute
wave: 2
depends_on: ["07-01", "07-02"]
files_modified:
  - tests/cli/test_cli_deploy_integration.py
  - src/configurable_agents/cli.py
autonomous: true

must_haves:
  truths:
    - "User can run `configurable-agents deploy` and deployment artifacts are generated"
    - "Subprocess tests verify actual CLI invocation (not just mocked function calls)"
    - "Docker availability is checked before attempting build"
    - "Port conflicts are detected and reported clearly"
    - "Generate-only mode creates artifacts without requiring Docker"
  artifacts:
    - path: "tests/cli/test_cli_deploy_integration.py"
      provides: "Subprocess integration tests for deploy command"
      exports: ["test_deploy_generate_only", "test_deploy_port_conflict", "test_deploy_docker_not_available"]
      min_lines: 100
    - path: "src/configurable_agents/cli.py"
      provides: "CLI deploy command implementation"
      contains: "def cmd_deploy"
  key_links:
    - from: "tests/cli/test_cli_deploy_integration.py"
      to: "configurable_agents.cli"
      via: "subprocess.run with sys.executable -m configurable_agents deploy"
      pattern: "subprocess\\.run\\(\\[sys\\.executable.*deploy"
    - from: "tests/cli/test_cli_deploy_integration.py"
      to: "cli.py:cmd_deploy"
      via: "Testing Docker checks and artifact generation"
      pattern: "docker|generate|artifact"
---

<objective>
Test and fix the CLI `deploy` command to ensure deployment artifacts are generated correctly with proper error handling.

**Purpose:** The `deploy` command generates Docker artifacts and optionally builds containers. It must check Docker availability, detect port conflicts, and provide clear feedback. This plan implements subprocess-based integration tests while avoiding actual Docker builds in automated tests.

**Output:**
- New `tests/cli/test_cli_deploy_integration.py` with subprocess-based tests
- Verified Docker availability checks work correctly
- Clear error messages for Docker/port issues
- Generate-only mode verified to work without Docker running
</objective>

<execution_context>
@C:\Users\ghost\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\ghost\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-cli-testing-and-fixes/07-RESEARCH.md

# Reference: Existing CLI Code
@tests/test_cli_deploy.py
@src/configurable_agents/cli.py
@src/configurable_agents/deploy/generator.py
</context>

<tasks>

<task type="auto">
  <name>Create subprocess integration test file for deploy command</name>
  <files>tests/cli/test_cli_deploy_integration.py</files>
  <action>
Create a new file `tests/cli/test_cli_deploy_integration.py` with subprocess-based integration tests for the `deploy` command.

**File structure:**
```python
"""
Integration tests for CLI deploy command using subprocess.

Tests actual CLI invocation for deployment artifact generation.
Avoids actual Docker builds in CI - focuses on artifact generation and error handling.
"""

import subprocess
import sys
from pathlib import Path

import pytest


class TestCLIDeployHelp:
    """Test deploy command help and argument parsing."""

    def test_deploy_help_shows_usage(self):
        """Test that --help works for deploy command."""
        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", "--help"],
            capture_output=True,
            text=True,
        )
        assert result.returncode == 0
        assert "usage:" in result.stdout.lower()

    def test_deploy_shows_generate_option(self):
        """Test deploy command shows --generate option."""
        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", "--help"],
            capture_output=True,
            text=True,
        )
        assert "--generate" in result.stdout

    def test_deploy_shows_port_options(self):
        """Test deploy command shows port configuration options."""
        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", "--help"],
            capture_output=True,
            text=True,
        )
        assert "port" in result.stdout.lower()


class TestCLIDeployErrors:
    """Test deploy command error handling."""

    def test_deploy_missing_file_clear_error(self):
        """Test deploy fails with clear error when config file doesn't exist."""
        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", "nonexistent.yaml"],
            capture_output=True,
            text=True,
        )

        assert result.returncode != 0
        # Clear error message
        assert "not found" in result.stderr.lower() or "no such file" in result.stderr.lower()

    def test_deploy_invalid_yaml_syntax(self, tmp_path):
        """Test deploy fails clearly on malformed YAML syntax."""
        config_file = tmp_path / "invalid.yaml"
        config_file.write_text("invalid: yaml: content: [unclosed")

        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", str(config_file), "--generate"],
            capture_output=True,
            text=True,
        )

        assert result.returncode != 0
        assert "yaml" in result.stderr.lower() or "syntax" in result.stderr.lower()


class TestCLIDeployGenerateOnly:
    """Test deploy --generate mode (artifact generation without build)."""

    def test_deploy_generate_creates_artifacts(self, tmp_path):
        """Test deploy --generate creates deployment artifacts."""
        config_file = tmp_path / "workflow.yaml"
        config_file.write_text("""
schema_version: "1.0"
flow:
  name: test_workflow
state:
  fields: []
nodes: []
edges: []
""")

        output_dir = tmp_path / "deploy_output"
        output_dir.mkdir()

        result = subprocess.run(
            [
                sys.executable, "-m", "configurable_agents", "deploy",
                str(config_file), "--generate",
                "--output-dir", str(output_dir)
            ],
            capture_output=True,
            text=True,
            timeout=60,
        )

        # Should succeed (generate-only doesn't require Docker)
        assert result.returncode == 0, f"stdout: {result.stdout}\nstderr: {result.stderr}"

        # Check artifacts created
        artifacts = list(output_dir.iterdir())
        assert len(artifactifacts) > 0, "No artifacts created"

        # Should have at least Dockerfile or server.py
        artifact_names = [f.name for f in artifacts]
        assert any(name in artifact_names for name in ["Dockerfile", "server.py", "requirements.txt"])

    def test_deploy_generate_verbose_output(self, tmp_path):
        """Test deploy --generate --verbose shows detailed progress."""
        config_file = tmp_path / "workflow.yaml"
        config_file.write_text("flow:\n  name: test\nstate:\n  fields: []\nnodes: []\nedges: []\n")

        output_dir = tmp_path / "deploy_output"
        output_dir.mkdir()

        result = subprocess.run(
            [
                sys.executable, "-m", "configurable_agents", "deploy",
                str(config_file), "--generate", "--verbose",
                "--output-dir", str(output_dir)
            ],
            capture_output=True,
            text=True,
            timeout=60,
        )

        assert result.returncode == 0
        # Verbose mode should show more output
        assert len(result.stdout) > 0 or len(result.stderr) > 0


class TestCLIDeployPortHandling:
    """Test deploy command port conflict detection."""

    def test_deploy_accepts_custom_ports(self, tmp_path):
        """Test deploy accepts custom port arguments."""
        config_file = tmp_path / "workflow.yaml"
        config_file.write_text("flow:\n  name: test\nstate:\n  fields: []\nnodes: []\nedges: []\n")

        # Just verify arguments are accepted (generate-only)
        result = subprocess.run(
            [
                sys.executable, "-m", "configurable_agents", "deploy",
                str(config_file), "--generate",
                "--api-port", "9999",
                "--mlflow-port", "5999"
            ],
            capture_output=True,
            text=True,
            timeout=60,
        )

        # Should accept the arguments (may fail for other reasons, but not port parsing)
        assert "invalid" not in result.stderr.lower() or result.returncode == 0


class TestCLIDeployDockerChecks:
    """Test deploy command Docker availability checks."""

    def test_deploy_docker_not_installed_message(self, tmp_path, monkeypatch):
        """
        Test deploy shows clear error when Docker is not available.

        Note: This test is difficult to run reliably in CI.
        We verify the error path exists by checking code.
        """
        # Verify cmd_deploy checks for Docker
        # Read cli.py and check for docker checks
        cli_path = Path("src/configurable_agents/cli.py")
        if cli_path.exists():
            cli_content = cli_path.read_text()
            # Should have docker check
            assert "docker" in cli_content.lower()
            # Should have error handling for docker not found
            assert "docker" in cli_content.lower() and ("not found" in cli_content.lower() or "unavailable" in cli_content.lower())

    @pytest.mark.slow
    def test_deploy_with_docker_available(self, tmp_path):
        """
        Test deploy works when Docker is available.

        This test is marked as slow and requires actual Docker.
        It may be skipped in CI but should run in local dev.
        """
        config_file = tmp_path / "workflow.yaml"
        config_file.write_text("""
schema_version: "1.0"
flow:
  name: test_workflow
state:
  fields: []
nodes: []
edges: []
""")

        # First check if Docker is available
        docker_check = subprocess.run(
            ["docker", "--version"],
            capture_output=True,
        )

        if docker_check.returncode != 0:
            pytest.skip("Docker not available")

        # Run deploy with --generate (safe even without full Docker setup)
        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", str(config_file), "--generate"],
            capture_output=True,
            text=True,
            timeout=60,
        )

        assert result.returncode == 0


class TestCLIDeployEnvFileHandling:
    """Test deploy command environment file handling."""

    def test_deploy_with_env_file(self, tmp_path):
        """Test deploy --env-file option."""
        config_file = tmp_path / "workflow.yaml"
        config_file.write_text("flow:\n  name: test\nstate:\n  fields: []\nnodes: []\nedges: []\n")

        env_file = tmp_path / ".env.test"
        env_file.write_text("API_KEY=test123\n")

        result = subprocess.run(
            [
                sys.executable, "-m", "configurable_agents", "deploy",
                str(config_file), "--generate",
                "--env-file", str(env_file)
            ],
            capture_output=True,
            text=True,
            timeout=60,
        )

        # Should accept env file argument
        assert result.returncode == 0 or "env" not in result.stderr.lower()

    def test_deploy_missing_env_file_warning(self, tmp_path):
        """Test deploy warns when default .env file is missing."""
        config_file = tmp_path / "workflow.yaml"
        config_file.write_text("flow:\n  name: test\nstate:\n  fields: []\nnodes: []\nedges: []\n")

        # Run from directory without .env file
        result = subprocess.run(
            [sys.executable, "-m", "configurable_agents", "deploy", str(config_file), "--generate"],
            capture_output=True,
            text=True,
            timeout=60,
        )

        # Should succeed (missing .env is not fatal in generate-only mode)
        # May show warning but should not error
        assert result.returncode == 0 or "warning" in result.stderr.lower() or "env" in result.stderr.lower()


class TestCLIDeployCrossPlatform:
    """Cross-platform compatibility tests for deploy command."""

    def test_deploy_path_with_spaces(self, tmp_path):
        """Test that output paths with spaces work on all platforms."""
        config_dir = tmp_path / "my folder" / "workflow"
        config_dir.mkdir(parents=True)
        config_file = config_dir / "config.yaml"
        config_file.write_text("flow:\n  name: test\nstate:\n  fields: []\nnodes: []\nedges: []\n")

        output_dir = tmp_path / "my folder" / "output"
        output_dir.mkdir(parents=True)

        result = subprocess.run(
            [
                sys.executable, "-m", "configurable_agents", "deploy",
                str(config_file), "--generate",
                "--output-dir", str(output_dir)
            ],
            capture_output=True,
            text=True,
            timeout=60,
        )

        # Should handle spaces correctly
        assert result.returncode == 0 or "path" not in result.stderr.lower()


class TestCLIDeployErrorMessageQuality:
    """Test that deploy error messages are helpful."""

    def test_docker_error_includes_install_instructions(self, tmp_path):
        """Test that Docker unavailable error includes installation guidance."""
        # This is verified by code inspection since we can't easily mock Docker
        cli_path = Path("src/configurable_agents/cli.py")
        if cli_path.exists():
            cli_content = cli_path.read_text().lower()
            # Check for helpful docker error messages
            # Should mention install, docker, or instructions
            docker_error_section = cli_content[cli_content.find("docker"):cli_content.find("docker") + 500]
            assert any(word in docker_error_section for word in ["install", "install docker", "https://", "docker.com"])

    def test_port_conflict_includes_port_number(self, tmp_path):
        """Test that port conflict error specifies which port."""
        # Verified by code inspection
        cli_path = Path("src/configurable_agents/cli.py")
        if cli_path.exists():
            cli_content = cli_path.read_text()
            # Should check ports and report conflicts
            assert "port" in cli_content.lower()
            assert "in use" in cli_content.lower() or "conflict" in cli_content.lower()
```

**Key patterns from RESEARCH.md:**
- Use `subprocess.run([sys.executable, "-m", "configurable_agents", "deploy", ...])` for actual CLI invocation
- Focus on `--generate` mode to avoid requiring actual Docker in CI
- Include slow tests that are skipped when Docker unavailable
- Verify error messages include actionable guidance
  </action>
  <verify>Run: python -m pytest tests/cli/test_cli_deploy_integration.py -v -m "not slow"</verify>
  <done>
    - File created at tests/cli/test_cli_deploy_integration.py
    - All test classes and methods defined
    - Tests use subprocess for actual CLI invocation
    - Tests focus on generate-only mode (no Docker required)
    - Error message quality tests included
  </done>
</task>

<task type="auto">
  <name>Verify Docker checks and error messages in cmd_deploy</name>
  <files>src/configurable_agents/cli.py</files>
  <action>
Review the `cmd_deploy` function in `src/configurable_agents/cli.py` to ensure Docker checks and error messages are clear.

**Check for:**
1. Docker availability check before attempting build
2. Clear error when Docker is not installed/unavailable
3. Port conflict detection with specific port numbers
4. Generate-only mode works without Docker
5. Environment file handling with clear warnings

**If Docker checks are missing, add:**
```python
# Check Docker availability
try:
    subprocess.run(["docker", "--version"], check=True, capture_output=True)
except (FileNotFoundError, subprocess.CalledProcessError):
    print_error("Docker is not installed or not running. Install Docker from https://docker.com or use --generate to create artifacts without building.")
    return 1
```

**Improve error messages if needed:**
- Port conflict: "Port {port} is already in use. Stop the conflicting service or use --api-port to specify a different port."
- Docker unavailable: "Docker is required for building. Install Docker or use --generate to create artifacts only."
  </action>
  <verify>Run: grep -n "docker\|port" src/configurable_agents/cli.py | head -30</verify>
  <done>
    - Docker availability check verified or added
    - Port conflict detection verified or added
    - Error messages include actionable guidance
    - Generate-only mode works without Docker
    - Environment file handling documented
  </done>
</task>

<task type="auto">
  <name>Run integration tests and verify deploy works correctly</name>
  <files>tests/cli/test_cli_deploy_integration.py</files>
  <action>
Execute the integration tests to verify deploy works correctly.

```bash
# Run the new test file (excluding slow tests that require Docker)
python -m pytest tests/cli/test_cli_deploy_integration.py -v -m "not slow"

# Run with coverage
python -m pytest tests/cli/test_cli_deploy_integration.py -m "not slow" --cov=src/configurable_agents/cli --cov-report=term-missing

# Run all tests if Docker is available (optional)
python -m pytest tests/cli/test_cli_deploy_integration.py -v
```

**Expected results:**
- Help tests pass (test_deploy_help_shows_usage, test_deploy_shows_generate_option, test_deploy_shows_port_options)
- Error tests pass (test_deploy_missing_file_clear_error, test_deploy_invalid_yaml_syntax)
- Generate-only tests pass (test_deploy_generate_creates_artifacts, test_deploy_generate_verbose_output)
- Port handling tests pass (test_deploy_accepts_custom_ports)
- Docker check tests pass (code inspection tests)
- Env file tests pass (test_deploy_with_env_file, test_deploy_missing_env_file_warning)
- Cross-platform tests pass (test_deploy_path_with_spaces)
- Error message quality tests pass (code inspection)
  </action>
  <verify>Run: python -m pytest tests/cli/test_cli_deploy_integration.py -v -m "not slow" && echo "Tests passed"</verify>
  <done>
    - All tests pass (except slow tests that may be skipped)
    - Coverage report shows cmd_deploy is well tested
    - Generate-only mode creates artifacts correctly
    - Error messages verified to be actionable
    - Cross-platform path handling works
  </done>
</task>

</tasks>

<verification>
After completing all tasks, verify:

1. New file `tests/cli/test_cli_deploy_integration.py` exists with at least 100 lines
2. Tests can be run with `pytest tests/cli/test_cli_deploy_integration.py`
3. Help/error/generate-only tests pass
4. Generate-only mode creates artifacts without requiring Docker
5. Docker availability checks are in place
6. Port conflict detection works
7. Cross-platform path handling tests included
8. Subprocess tests actually invoke the CLI (not just imports)
9. Run `pytest -k "test_cli_deploy" --collect-only` to see all tests collected
</verification>

<success_criteria>
Phase 07-03 succeeds when:

1. **CLI-04 satisfied**: User can run `configurable-agents deploy` and deployment artifacts are generated
2. **CLI-06 satisfied**: Deploy error messages are clear, actionable, and include resolution steps
3. Subprocess integration tests exist for deploy command
4. Generate-only mode works without Docker installed
5. Docker availability checks prevent confusing errors
6. Port conflicts are detected and reported clearly
7. Tests pass on Windows (path handling works correctly)
8. Coverage of cmd_deploy function increased by at least 20%
</success_criteria>

<output>
After completion, create `.planning/phases/07-cli-testing-and-fixes/07-03-SUMMARY.md` with:
- Tests created (count by class)
- Docker check improvements made
- Coverage improvement metrics
- Artifact generation verification status
</output>
